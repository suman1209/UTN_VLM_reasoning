{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0833d1e6-e58c-4d66-bce9-1ad02b7ef476",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "## other standard packages\n",
    "import sys\n",
    "## Env variables and preparation stuffs\n",
    "sys.path.insert(0, \"../\")\n",
    "from src_code.data_utils.dataset import GridDataset\n",
    "from src_code.data_utils.dataset_utils import CellType, draw_image_grid\n",
    "from src_code.data_utils.prompt_utils import prompt_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137977c-ca7b-46a2-8e14-6dcab4274c35",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "class CellType(Enum):\n",
    "\n",
    "    FREE_CELL = 1  # Represents free space\n",
    "    WALL = 2       # Represens a wall\n",
    "    START = 3      # Represents the start position\n",
    "    GOAL = 4       # Represents the goal position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa20a2b-d8b0-40d1-a90a-bf42b52e1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell size in the size of the grid measured in pixels\n",
    "dataset = GridDataset(grid_size=5, seed = 42, wall_symbol=\"#\", free_symbol=\".\", cell_size=10)\n",
    "img_rgb1, grid_world1 = dataset[0]\n",
    "img_rgb2, grid_world2 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f0681-79f7-4fe5-9783-874239fc539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 6\n",
    "img_title_pairs = [(dataset[i][0], f\"{dataset[i][1].a_star()}\") for i in range(num_images)]\n",
    "draw_image_grid(img_title_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48695ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(grid_world2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824e8a0",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5236802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_generator(grid_world2, img=img_rgb2, img_symbol=\"<image>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_generator(grid_world2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca8471-8073-4aa4-ab99-b1f9cd3243ed",
   "metadata": {},
   "source": [
    "# Images for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ed9e6-2030-42c1-80ad-48b4c4005e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GridDataset(grid_size=5, seed = 42, wall_symbol=\"#\", free_symbol=\".\", cell_size=50)\n",
    "img_rgb5, grid_world5 = dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6f95d-0bc2-45e4-b5c5-0b45dac019dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6436f6b-bff6-417f-9e02-f9b259cfc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(grid_world5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c02f6c-def2-4150-aa44-1734cfcb6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_world5.a_star()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01651d-4eb5-4d44-b6bb-6028c38ecbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_generator(grid_world5, pure_language=False, img=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f79f46-38a1-40ab-bb7a-10fc0002f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"<api_key>\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5745ec-509b-403d-8ccb-bc630b791624",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "with open(\"deep_seek_outputs_ascii.txt\", \"w\") as f0:\n",
    "    for i in range(num_points):\n",
    "        img_rgb, grid_world = dataset[i]\n",
    "        prompt = prompt_generator(grid_world, pure_language=False, img=None)\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "        ],\n",
    "        stream=False)\n",
    "        ans = response.choices[0].message.content\n",
    "        f0.write( ans + \"search term \\n\")\n",
    "        print(f\"response={i} {ans}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f4478-f629-4058-807e-cb0731814472",
   "metadata": {},
   "source": [
    "## DeepSeek-R1-Distill-Llama-8B\n",
    "env: gemma3-4b\n",
    "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
    "\n",
    "Memory Issue in CIP pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d83bb3-d71e-43d3-8ceb-124ebaaa44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
