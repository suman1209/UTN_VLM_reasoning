{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6ac40750d242aea3a5e3517eafd26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from src_code.data_utils.dataset import GridDataset\n",
    "from src_code.data_utils.dataset_utils import CellType\n",
    "from src_code.data_utils.prompt_utils import prompt_generator\n",
    "from src_code.model_utils.gemma3 import Gemma3Model\n",
    "from src_code.eval_utils.eval import calculate_score, eval_results\n",
    "\n",
    "import ast\n",
    "\n",
    "model = Gemma3Model()\n",
    "EVAL_NUM = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuslt = model.inference(\n",
    "    \"Describe this image in detail.\", \n",
    "    img=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n",
    ")\n",
    "print(reuslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GridDataset(grid_size=5, seed = 42, wall_symbol=\"#\", free_symbol=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASCII Input Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the grid world:\n",
      " # # # # # # #\n",
      " # . . . . . #\n",
      " # # . . . . #\n",
      " # . # . . . #\n",
      " # . . . G . #\n",
      " # S . # . . #\n",
      " # # # # # # #\n",
      "\n",
      "The S cell is the starting cell,\n",
      "the G cell is the goal cell,\n",
      "the # cells are obstacles,\n",
      "and the . cells are free cells.\n",
      "\n",
      "Rules:\n",
      "The grid size is 5x5\n",
      "The path must not pass through the obstacles.\n",
      "You can move up, down, left, or right from one cell to another.\n",
      "You cannot move diagonally.\n",
      "The path must be the shortest path from the starting cell to the goal cell.\n",
      "The output should be a sequence of steps to reach the goal cell.\n",
      "Output the steps only.\n",
      "\n",
      "Actions:\n",
      "Only give me the steps, like 'go up', 'go down', 'go left', 'go right' or 'not solvable'\n",
      "go up: move one cell up\n",
      "go down: move one cell down\n",
      "go left: move one cell left\n",
      "go right: move one cell right\n",
      "not solvable: it is not possible to go the the goal cell from the start cell\n",
      "\n",
      "Output example:\n",
      "('go up', 'go right', 'go right', 'go down', 'go right') or ('not solvable')\n",
      "\n",
      "Can you find the path from the starting cell to the goal cell?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img, grid_world = dataset[10]\n",
    "prompt_img = prompt_generator(grid_world, pure_language=False, img=None, img_symbol=\"This image\")\n",
    "print(prompt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAABGCAIAAAD+THXTAAABBElEQVR4Ae2aQQ7CMAwEE16en4cWuO9GotrEGs5Lbc+klVW1tXK/fk0055Rz9X5M8iWHOS7ASCcowxKWIgQ4eBHsi0WxtAgsEi9oKcKRoosE7v16jCH/9c0csbMXvJcYSR7QDQJY2kCCbAFLEtEGASxtIEG2gCWJiAAELAJrb7qP2Nl5PFjmwyEshQVY5bFkYQqHsBQWYJXHkoUpHCpoKUyU8haBtU38iXfiTX8a09rdpvsVTcF7iZGswxwOYSkswCqPJQtTOISlsACrPJYsTIQgIAl8NnGZ+q3C7i58XS/49pzHg+EzHsFSXIHRAJYMSPEIluIKjAawZECKRwpaijP9fwNvtBdHdCHuncAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuslt = model.inference(prompt_img, img=None)\n",
    "print(reuslt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results_img = []\n",
    "path_results_ascii = []\n",
    "path_results_coor = []\n",
    "path_results_img_raw = []\n",
    "path_results_ascii_raw = []\n",
    "path_results_coor_raw = []\n",
    "EVAL_NUM = 1\n",
    "for i in range(EVAL_NUM):\n",
    "    img_rgb, grid_world = dataset[i]\n",
    "    prompt_img = prompt_generator(grid_world, pure_language=False, img=True, img_symbol=\"This image\")\n",
    "    prompt_ascii = prompt_generator(grid_world, pure_language=False)\n",
    "    prompt_coor = prompt_generator(grid_world, pure_language=True)\n",
    "    path_result_img = model.inference(\n",
    "        prompt_img, \n",
    "        img=img_rgb\n",
    "    )\n",
    "    patj_result_ascii = model.inference(\n",
    "        prompt_ascii\n",
    "    )\n",
    "    path_result_coor = model.inference(\n",
    "        prompt_coor\n",
    "    )\n",
    "    path_results_img_raw.append(path_result_img)\n",
    "    path_results_ascii_raw.append(patj_result_ascii)\n",
    "    path_results_coor_raw.append(path_result_coor)\n",
    "    try:\n",
    "        print(f\"{path_result_img=}\")\n",
    "        path_result_img = ast.literal_eval(path_result_img)\n",
    "        print(f\"{path_result_img=}\")\n",
    "        path_results_img.append(path_result_img)\n",
    "    except Exception as e:\n",
    "        print(f\"{e=}\")\n",
    "        print(f\"Fail to parse path_result_img\")\n",
    "    try:\n",
    "        print(f\"{patj_result_ascii=}\")\n",
    "        path_result_ascii = ast.literal_eval(patj_result_ascii)\n",
    "        path_results_ascii.append(path_result_ascii)\n",
    "        print(f\"{path_result_ascii=}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{e=}\")\n",
    "        print(f\"Fail to parse path_result_ascii\")\n",
    "    try:\n",
    "        print(f\"{path_result_coor=}\")\n",
    "        path_result_coor = ast.literal_eval(path_result_coor)\n",
    "        print(f\"{path_result_coor=}\")\n",
    "        path_results_coor.append(path_result_coor)\n",
    "    except Exception as e:\n",
    "        print(f\"{e=}\")\n",
    "        print(f\"Fail to parse path_result_coor\")\n",
    "    print(f\"{grid_world.a_star()=}\\n\")\n",
    "\n",
    "eval_result_img = eval_results(path_results_img, dataset)\n",
    "eval_result_ascii = eval_results(path_results_ascii, dataset)\n",
    "eval_result_coor = eval_results(path_results_coor, dataset)\n",
    "print(f\"{eval_result_img=}\")\n",
    "print(f\"{eval_result_ascii=}\")\n",
    "print(f\"{eval_result_coor=}\")\n",
    "result = {\"img\": eval_result_img, \"ascii\": eval_result_ascii, \"coor\": eval_result_coor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../result_gemma3_100.json', 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "with open('../gemma3_results_img_raw.json', 'w') as f:\n",
    "    json.dump(path_results_img_raw, f, indent=4)\n",
    "\n",
    "with open('../gemma3_results_ascii_raw.json', 'w') as f:\n",
    "    json.dump(path_results_ascii_raw, f, indent=4)\n",
    "\n",
    "with open('../gemma3_results_coor_raw.json', 'w') as f:\n",
    "    json.dump(path_results_coor_raw, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import json\n",
    "from src_code.data_utils.dataset import GridDataset\n",
    "from src_code.eval_utils.eval import calculate_score, eval_results\n",
    "import ast\n",
    "dataset = GridDataset(grid_size=5, seed = 42, wall_symbol=\"#\", free_symbol=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "path_results_img = []\n",
    "path_results_ascii = []\n",
    "path_results_coor = []\n",
    "with open('../gemma3_results_img_raw.json', 'r') as f:\n",
    "    path_results_img_raw = json.load(f)\n",
    "\n",
    "with open('../gemma3_results_ascii_raw.json', 'r') as f:\n",
    "    path_results_ascii_raw = json.load(f)\n",
    "\n",
    "with open('../gemma3_results_coor_raw.json', 'r') as f:\n",
    "    path_results_coor_raw = json.load(f)\n",
    "\n",
    "for i, content in enumerate(path_results_img_raw):\n",
    "    r = None\n",
    "    try:\n",
    "        r = ast.literal_eval(content)\n",
    "        if type(r) == str:\n",
    "            r = (r,)\n",
    "    except Exception as e:\n",
    "        print(\"Imgae result parsing error\")\n",
    "    path_results_img.append(r)\n",
    "\n",
    "for i, content in enumerate(path_results_ascii_raw):\n",
    "    r = None\n",
    "    try:\n",
    "        r = ast.literal_eval(content)\n",
    "        if type(r) == str:\n",
    "            r = (r,)\n",
    "    except Exception as e:\n",
    "        print(\"Ascii result parsing error\")\n",
    "    path_results_ascii.append(r)\n",
    "\n",
    "for i, content in enumerate(path_results_coor_raw):\n",
    "    r = None\n",
    "    try:\n",
    "        r = ast.literal_eval(content)\n",
    "        if type(r) == str:\n",
    "            r = (r,)\n",
    "    except Exception as e:\n",
    "        print(\"coor result parsing error\")\n",
    "    path_results_coor.append(r)\n",
    "\n",
    "eval_result_img = eval_results(path_results_img, dataset)\n",
    "eval_result_ascii = eval_results(path_results_ascii, dataset)\n",
    "eval_result_coor = eval_results(path_results_coor, dataset)\n",
    "print(f\"{eval_result_img=}\")\n",
    "print(f\"{eval_result_ascii=}\")\n",
    "print(f\"{eval_result_coor=}\")\n",
    "result = {\"img\": eval_result_img, \"ascii\": eval_result_ascii, \"coor\": eval_result_coor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
